# optional ports are specified throughout for more advanced use cases.

services:
  minio-service:
    container_name: budi-minio-dev
    restart: on-failure
    image: minio/minio
    volumes:
      - minio_data:/data
    ports:
      - "${MINIO_PORT}:9000"
      - "9001:9001"
    environment:
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  proxy-service:
    container_name: budi-nginx-dev
    restart: on-failure
    image: budibase/proxy:latest
    volumes:
      - ./nginx.dev.conf:/etc/nginx/templates/nginx.conf.template
      - ./proxy/error.html:/usr/share/nginx/html/error.html
    ports:
      - "${MAIN_PORT}:10000"
    depends_on:
      - minio-service
      - couchdb-service
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - PROXY_ADDRESS=host.docker.internal

  couchdb-service:
    container_name: budi-couchdb3-dev
    restart: on-failure
    image: budibase/database:2.0.0
    environment:
      - COUCHDB_PASSWORD=${COUCH_DB_PASSWORD}
      - COUCHDB_USER=${COUCH_DB_USER}
      - DATA_DIR=/data
    ports:
      - "${COUCH_DB_PORT}:5984"
      - "${COUCH_DB_SQS_PORT}:4984"
    volumes:
      - couchdb_data:/data

  redis-service:
    container_name: budi-redis-dev
    restart: on-failure
    image: redis
    command: redis-server --requirepass ${REDIS_PASSWORD}
    ports:
      - "${REDIS_PORT}:6379"
    volumes:
      - redis_data:/data

  litellm-service:
    container_name: budi-litellm-dev
    image: docker.litellm.ai/berriai/litellm:1.80.15-stable.1
    ports:
      - "${LITELLM_PORT:-4000}:4000"
    volumes:
      - ./litellm_config.yaml:/app/config.yaml
    environment:
      DATABASE_URL: "postgresql://llmproxy:dbpassword9090@litellm-db:5432/litellm"
      STORE_MODEL_IN_DB: "True" # allows adding models to proxy via UI
      LITELLM_REASONING_AUTO_SUMMARY: "true" # enables reasoning summaries for Responses API models
      BBAI_URL: http://host.docker.internal:10000/api/ai
    command: ["--config", "/app/config.yaml"]
    env_file:
      - .env
    depends_on:
      - litellm-db
    healthcheck:  
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 http://localhost:4000/health/liveliness || exit 1" ]  # Command to execute for health check
      interval: 30s
      timeout: 10s 
      retries: 3   
      start_period: 40s

  litellm-db:
    image: postgres:16
    restart: always
    environment:
      POSTGRES_DB: litellm
      POSTGRES_USER: llmproxy
      POSTGRES_PASSWORD: dbpassword9090
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d litellm -U llmproxy"]
      interval: 1s
      timeout: 5s
      retries: 10

volumes:
  couchdb_data:
    driver: local
  minio_data:
    driver: local
  redis_data:
    driver: local
